episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,50,-10.467806828056517,1.0722914600948332,0.0018162131309509277,50
2,False,50,-6.698661759222152,1.0778313811235172,0.0019562339782714846,50
3,True,18,-2.4226527941171323,1.0334208370866327,0.0018885466787550184,50
4,False,50,-6.2302831880316205,1.0029103041617067,0.0016934704780578614,50
5,False,50,-7.290540931955879,0.9441690641384299,0.0018395090103149414,50
6,False,50,-6.686426436979839,0.8698180077710966,0.0018178796768188476,50
7,False,50,-6.2810538097998245,0.8216096785847387,0.0016585183143615722,50
8,False,50,-7.086856266156375,0.7725619211998485,0.0016402339935302735,50
9,False,50,-7.046162774976128,0.7324154556263063,0.0016466903686523438,50
10,False,50,-5.846135937964064,0.6902109887191354,0.0019310545921325684,50
