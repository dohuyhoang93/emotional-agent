episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,True,143,-10.165704803499988,0.9883117468856656,0.0,200
2,True,275,-22.193712562068754,0.6223086834028266,0.0,200
