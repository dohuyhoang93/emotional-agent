episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,500,-76.9341239882006,0.3089086853805554,0.0,500
2,False,500,-56.226709937504395,0.2411423962178395,0.0,500
3,False,500,-63.428527674598186,0.17211421014709938,0.0,500
4,False,500,-60.217728026573496,0.21151416398498188,0.0,500
5,False,500,-59.77684358217043,0.19378275232929199,0.0,500
6,False,500,-57.935445703665394,0.23761200563167872,0.0,500
7,False,500,-61.174473097238234,0.22323464770217377,0.0,500
8,False,500,-61.47957582607254,0.20395314889481128,0.0,500
9,False,500,-59.88018618678264,0.21719145790831856,0.0,500
10,False,500,-65.3865168385771,0.22164243461005917,0.0,500
