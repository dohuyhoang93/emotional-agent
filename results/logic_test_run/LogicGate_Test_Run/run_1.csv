episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,500,-77.89645835076846,0.30125899546775936,0.0,500
2,False,500,-60.454834582478156,0.22895646501209,0.0,500
3,False,500,-57.354343560238924,0.22747634531898964,0.0,500
4,False,500,-57.04759811071024,0.2273062060019649,0.0,500
5,False,500,-59.519179427619136,0.23256734567302673,0.0,500
6,False,500,-58.363226649288386,0.23851018802379909,0.0,500
7,False,500,-63.49697293833366,0.23365497012038666,0.0,500
8,False,500,-60.75567911972093,0.2269030530982262,0.0,500
9,False,500,-61.973432249113856,0.2151982487847071,0.0,500
10,False,500,-59.21747890472054,0.2169457972180151,0.0,500
