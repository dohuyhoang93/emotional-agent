episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,500,-63.94984471369042,0.2618555867019665,0.0,500
2,False,500,-62.31024064716458,0.14572793651248672,0.0,500
3,False,500,-55.50054473461713,0.09119440795822609,0.0,500
4,False,500,-58.56249179683022,0.08607165910216938,0.0,500
5,False,500,-54.8015729537922,0.10379908042568176,0.0,500
6,False,500,-58.84643502390982,0.07457208291744534,0.0,500
7,False,500,-53.858842775208295,0.150311106633143,0.0,500
8,False,500,-56.810921146908676,0.1728396733336693,0.0,500
9,False,500,-55.21631894710471,0.11176010982291512,0.0,500
10,False,500,-53.115630467804074,0.1380326450001501,0.0,500
