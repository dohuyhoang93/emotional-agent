--- MULTI-AGENT EXPERIMENT SUMMARY ---
Output directory: results

=== Experiment: sleep_debug ===
  Runs: 1
  Episodes per run: 6
  Parameters: {'num_agents': 2, 'sleep_interval': 2, 'sleep_duration': 10, 'environment_config': {'grid_size': 10, 'num_agents': 2, 'max_steps_per_episode': 20, 'goal_pos': [9, 9], 'start_positions': [[0, 0], [0, 1]], 'walls': [], 'logical_switches': [], 'dynamic_walls': []}}

  Total Episodes: 6
  Final Avg Reward: 5.4000
  Best Reward Achieved: 0.0000

  Social Learning:
    Total Transfers: 0
    Total Synapses: 0

  Revolution Protocol:
    Total Revolutions: 0

  Learning Trend (every 10%):
    Episodes 0-1: Avg Reward = 1.4573
    Episodes 1-2: Avg Reward = 0.9500
    Episodes 2-3: Avg Reward = 4.0000
    Episodes 3-4: Avg Reward = 3.6000
    Episodes 4-5: Avg Reward = 3.2000
    Episodes 5-6: Avg Reward = 5.4000

