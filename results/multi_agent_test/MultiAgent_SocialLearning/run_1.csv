episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,500,-34.2167216658975,1.1062270654277646,0.0022976064682006837,500
2,False,500,-32.56832530331431,0.8675112548571589,0.001508052349090576,500
3,True,94,-6.8713369499382795,0.8345076730348788,0.0018323837442600981,500
4,False,500,-28.750025929365925,0.7027876049870045,0.0014703640937805177,500
5,False,500,-27.697759399202024,0.6229353346763964,0.0015451064109802245,500
6,True,191,-2.9335664241810555,0.6014398717508983,0.001283781690747326,500
7,True,393,-11.854862717820811,0.5683794061953804,0.0014441723131951485,500
8,True,249,-2.234017676036757,0.5532406054976595,0.0013632841378330705,500
9,True,269,-3.97128103479964,0.5406317997825048,0.0016577766730439707,500
10,True,117,5.196372764727508,0.5361050537398901,0.0016842886932894716,500
