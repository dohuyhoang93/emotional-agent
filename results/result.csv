episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,200,-25.204647583899995,0.8656830229622512,0.0,200
2,False,200,-27.067347046127445,0.6335500173761024,0.0,200
3,True,119,-12.92438247291372,0.5728353845760625,0.0,200
4,False,200,-24.21121731946397,0.5271737615653613,0.0,200
5,False,200,-20.11808695770169,0.5096450548506157,0.0,200
6,False,200,-23.15583824705156,0.503461964590155,0.0,200
7,False,200,-22.709429802066275,0.5013447559430946,0.0,200
8,False,200,-20.889467029243182,0.5004683140227777,0.0,200
9,False,200,-22.372903919882976,0.5001608817880837,0.0,200
10,False,200,-24.699401191344208,0.4999135679438136,0.0,200
