episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,200,-24.8445256339,0.673385509132707,0.0,200
2,False,200,-26.29862675836241,0.4135761155073046,0.0,200
3,False,200,-20.482933294509017,0.37109639447484566,0.0,200
4,False,200,-20.837536358543634,0.3617314970350629,0.0,200
5,False,200,-20.478556570643732,0.2966858785214589,0.0,200
6,False,200,-20.106173581258094,0.35877735086797463,0.0,200
7,False,200,-26.28447622576902,0.32516096888737883,0.0,200
8,False,200,-21.55488556129566,0.3547808715937463,0.0,200
9,False,200,-21.241630289560494,0.2817713174272699,0.0,200
10,False,200,-20.846886671282846,0.2907013336560405,0.0,200
