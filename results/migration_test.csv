episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,200,-24.8445256339,0.673385509132707,0.0,200
2,False,200,-26.29862675836241,0.4135761155073046,0.0,200
