episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,True,380,-21.626164999019586,1.1836012443669741,0.0014605340204740826,500
2,False,500,-36.53267881448185,0.9144175762953586,0.0015492105484008788,500
3,True,234,-17.27300863464128,0.8278774109492142,0.0013841105322552542,500
4,True,149,0.15023292974638736,0.7821643185451634,0.0016074100596792746,500
5,False,500,-27.043235130822563,0.6710556468000592,0.0017327313423156738,500
6,False,500,-30.17571392205091,0.6036985627844481,0.0016432104110717773,500
7,True,195,0.7139608303828542,0.5852247593275207,0.001571047611725636,500
8,False,500,-27.792683389535796,0.5516655557489104,0.001718435287475586,500
9,True,226,-12.58387345044411,0.5412052231827309,0.001439707469096226,500
10,True,467,-14.10740571967162,0.5257928262170921,0.0013321783609002253,500
