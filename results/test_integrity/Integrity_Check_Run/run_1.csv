episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,20,-5.3118,1.3495062842029928,0.0,20
2,False,20,-5.343526774499999,1.3155139480836568,0.0,20
3,False,20,-3.8905877145000005,1.2386307420239284,0.0,20
4,False,20,-8.495821205065301,1.1661604251150863,0.0,20
5,False,20,-5.033071860700856,1.1055380691800547,0.0,20
