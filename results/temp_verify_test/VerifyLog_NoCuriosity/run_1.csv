episode,success,steps,total_reward,final_exploration_rate,avg_cycle_time,max_steps_env
1,False,500,-58.70000000000053,0.7787520933134615,0.0012987852096557617,500
2,False,500,-61.500000000000455,0.606454822840097,0.0012767162322998046,500
3,True,213,-12.400000000000038,0.5451732332993653,0.0012884050467764268,500
4,False,500,-59.50000000000046,0.42455479665034745,0.0012557263374328614,500
5,False,500,-55.90000000000045,0.33062293661772796,0.0012664003372192382,500
